You mentioned that taking into account for artist and dimension of the work in your model, which is good. But details about how this is incorporated is not clear. From your code, it seems like you are getting an one-hot encoding out of the artists and concatenate the coding to the first FC layer in your model for the inference. The better plan could be to actually embed artists, and only concatenate the embeddings other than the encoding. This could be useful several folds: 1) handles unknown artists automatically (just like <unk> token) so you don't need to hard code a 5197 dim in your FC (solve one challenges that you mentioned). 2) Your embedding size can be a lot smaller like 128 for example, so the mojority contribution from this FC is from the resnet out (which is evaluated on the artist value of the work itself), now your 5197 sized encoding is so large and dominates the FC inputs. 
